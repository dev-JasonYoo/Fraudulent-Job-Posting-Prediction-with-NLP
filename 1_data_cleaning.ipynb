{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1e795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title            location  \\\n",
       "0                           Marketing Intern    US, NY, New York   \n",
       "1  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
       "2    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
       "3          Account Executive - Washington DC  US, DC, Washington   \n",
       "4                        Bill Review Manager  US, FL, Fort Worth   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  telecommuting  \\\n",
       "0  Experience with content management systems a m...              0   \n",
       "1  What we expect from you:Your key responsibilit...              0   \n",
       "2  Implement pre-commissioning and commissioning ...              0   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...              0   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...              0   \n",
       "\n",
       "   has_company_logo  has_questions  fraudulent  \n",
       "0                 1              0           0  \n",
       "1                 1              0           0  \n",
       "2                 1              0           0  \n",
       "3                 1              0           0  \n",
       "4                 1              1           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "##### Merging two datasets #####\n",
    "################################\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"fake_job_postings.csv\", na_values=\"<NA>\", index_col=False)\n",
    "df1.drop(['benefits', 'company_profile', 'employment_type', 'salary_range',\n",
    "          'industry', 'department', 'required_experience', 'required_education', 'job_id', 'function',], axis=1, inplace=True)\n",
    "df2 = pd.read_csv(\"job_train.csv\", na_values=\"<NA>\", index_col=False)\n",
    "df2 = df2[df2['fraudulent']==1]\n",
    "merged_df = pd.concat([df1, df2])\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "merged_df = merged_df.fillna(pd.NA)\n",
    "# merged_df.to_csv(\"final_data.csv\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6587e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "##### Define Functions #####\n",
    "############################\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "def remove_accents(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    # Normalize to NFD (decompose accented chars), then filter out combining marks\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', str(text))\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_accents(column, print_change):\n",
    "    cleaned_lst = []\n",
    "    for val in merged_df[column]:\n",
    "        if not pd.isna(val) and str(val).strip() != \"\": \n",
    "            cleaned_val = remove_accents(val)\n",
    "            if val != cleaned_val:\n",
    "                cleaned_lst.append((val, cleaned_val))\n",
    "    cleaned_lst = list(set(cleaned_lst))\n",
    "    if print_change:\n",
    "        for cleaned in cleaned_lst:\n",
    "            print(cleaned)\n",
    "\n",
    "def has_non_latin(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    for char in text:\n",
    "        if ord(char) > 127:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def remove_non_latin(text):\n",
    "    if pd.isna(text):\n",
    "        return pd.NA\n",
    "    cleaned_text = \"\"\n",
    "    for char in text:\n",
    "        if ord(char) > 127:\n",
    "            continue\n",
    "        cleaned_text += char\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ff8130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>location_has_non_latin</th>\n",
       "      <th>description_has_non_latin</th>\n",
       "      <th>requirements_has_non_latin</th>\n",
       "      <th>has_requirements</th>\n",
       "      <th>description_and_requirements</th>\n",
       "      <th>country_state</th>\n",
       "      <th>country</th>\n",
       "      <th>has_location</th>\n",
       "      <th>has_location_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>US, NY</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NZ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>US, IA</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>THE COMPANY: ESRI  Environmental Systems Resea...</td>\n",
       "      <td>EDUCATION:Bachelors or Masters in GIS, busines...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>THE COMPANY: ESRI  Environmental Systems Resea...</td>\n",
       "      <td>US, DC</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>US, FL</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title            location  \\\n",
       "0                           Marketing Intern    US, NY, New York   \n",
       "1  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
       "2    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
       "3          Account Executive - Washington DC  US, DC, Washington   \n",
       "4                        Bill Review Manager  US, FL, Fort Worth   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI  Environmental Systems Resea...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  telecommuting  \\\n",
       "0  Experience with content management systems a m...              0   \n",
       "1  What we expect from you:Your key responsibilit...              0   \n",
       "2  Implement pre-commissioning and commissioning ...              0   \n",
       "3  EDUCATION:Bachelors or Masters in GIS, busines...              0   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...              0   \n",
       "\n",
       "   has_company_logo  has_questions  fraudulent  location_has_non_latin  \\\n",
       "0                 1              0           0                       0   \n",
       "1                 1              0           0                       0   \n",
       "2                 1              0           0                       0   \n",
       "3                 1              0           0                       0   \n",
       "4                 1              1           0                       0   \n",
       "\n",
       "   description_has_non_latin  requirements_has_non_latin  has_requirements  \\\n",
       "0                          0                           0              True   \n",
       "1                          1                           1              True   \n",
       "2                          0                           1              True   \n",
       "3                          1                           1              True   \n",
       "4                          1                           1              True   \n",
       "\n",
       "                        description_and_requirements country_state country  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...        US, NY      US   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...           NaN      NZ   \n",
       "2  Our client, located in Houston, is actively se...        US, IA      US   \n",
       "3  THE COMPANY: ESRI  Environmental Systems Resea...        US, DC      US   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...        US, FL      US   \n",
       "\n",
       "   has_location  has_location_details  \n",
       "0          True                 False  \n",
       "1          True                 False  \n",
       "2          True                 False  \n",
       "3          True                 False  \n",
       "4          True                 False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "##### Data Processing #####\n",
    "###########################\n",
    "\n",
    "# drop rows with missing description (18336 --> 18334 samples)\n",
    "merged_df = merged_df.dropna(subset=['description'])\n",
    "\n",
    "### Text Columns ###\n",
    "\n",
    "# convert accents to basic latin\n",
    "text_cols = ['location', 'description', 'requirements']\n",
    "for col in text_cols:\n",
    "    clean_accents(col, False)\n",
    "\n",
    "# mask and remove non-basic-latin\n",
    "for col in text_cols:\n",
    "    merged_df[f\"{col}_has_non_latin\"] = merged_df[col].apply(has_non_latin)\n",
    "    merged_df[col] = merged_df[col].apply(remove_non_latin)\n",
    "\n",
    "# Make new feature that has binary value for whether requirements was missing or not\n",
    "merged_df[\"has_requirements\"] = merged_df[\"requirements\"].notna()\n",
    "# Merge description with requirements so they are in one new feature - called description_and_requirements\n",
    "merged_df[\"description_and_requirements\"] = merged_df[\"description\"] + merged_df[\"requirements\"].fillna(\"\")\n",
    "\n",
    "### LOCATION ###\n",
    "\n",
    "# Extract country and state\n",
    "pattern1 = r'(^[A-Z]{2},\\s*[A-Z0-9]{1,3})'\n",
    "merged_df['country_state'] = merged_df['location'].str.extract(pattern1, expand=False)\n",
    "# Extract country\n",
    "pattern2 = r'(^[A-Z]{2})'\n",
    "merged_df['country'] = merged_df['location'].str.extract(pattern2, expand=False)\n",
    "# Manage Remote jobs\n",
    "merged_df['is_remote'] = merged_df['location'].str.lower().str.contains('remote|work from home', na=False) & merged_df['country_state'].isna()\n",
    "merged_df.loc[merged_df['is_remote'], 'country_state'] = \"Remote\"\n",
    "merged_df.loc[merged_df['is_remote'], 'country'] = \"Remote\"\n",
    "merged_df.drop(columns=[\"is_remote\"], inplace=True)\n",
    "\n",
    "# New column - location mask\n",
    "merged_df[\"has_location\"] = merged_df[\"location\"].notna()\n",
    "# New column - detailed location mask - something beyond just the country code\n",
    "merged_df[\"has_location_details\"] = (merged_df[\"location\"].str.lower().str.strip() == merged_df[\"country\"].str.lower().str.strip()).fillna(False)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4150e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.to_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb7616b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are some 14 country names with commas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BO           Bolivia, Plurinational State of\n",
       "BQ          Bonaire, Sint Eustatius and Saba\n",
       "CD         Congo, Democratic Republic of the\n",
       "IR                 Iran, Islamic Republic of\n",
       "KP    Korea, Democratic People's Republic of\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The commas are cleaned now, as shown below\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BO    Bolivia\n",
       "BQ    Bonaire\n",
       "CD      Congo\n",
       "IR       Iran\n",
       "KP      Korea\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally, ISO code to country name mapping looks like this\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AL      Albania\n",
       "AR    Argentina\n",
       "AM      Armenia\n",
       "AU    Australia\n",
       "AT      Austria\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check for the inverse mapping: True\n"
     ]
    }
   ],
   "source": [
    "# make a mapping from 2-letter abbreviations to full country names\n",
    "iso_df = pd.read_csv(\"ISO3166.csv\")\n",
    "iso_series = pd.Series(iso_df[\"name\"].apply(remove_accents).values, index=iso_df[\"alpha-2\"].values)     # remove accents\n",
    "\n",
    "# data cleaning\n",
    "countries_with_comma = iso_series[iso_series.apply(lambda x: ',' in x)].index\n",
    "print(f\"There are some {len(iso_series[countries_with_comma])} country names with commas\")\n",
    "display(iso_series[countries_with_comma].head())\n",
    "\n",
    "iso_series = iso_series.apply(lambda x: x.split(',')[0] if ',' in x else x)                             # get the 'main' name\n",
    "\n",
    "print(f'The commas are cleaned now, as shown below')\n",
    "display(iso_series[countries_with_comma].head())\n",
    "\n",
    "iso_series = iso_series[iso_series.index.isin(merged_df[\"country\"].to_list())]                          # save only the existing ones\n",
    "iso_dict = iso_series.to_dict()                                                                         # conver to dict\n",
    "print('Finally, ISO code to country name mapping looks like this')\n",
    "display(iso_series.head())\n",
    "\n",
    "# there must be no overlapping in both keys and values (so there can be a valid inverse mapping)\n",
    "print(f'Sanity check for the inverse mapping: {\n",
    "    len(set(iso_dict.keys())) == len(set(iso_dict.values()))\n",
    "}')\n",
    "country_dict = {country: code for country, code in zip(iso_dict.values(), iso_dict.keys())}\n",
    "\n",
    "# manual updates\n",
    "country_dict.update({\n",
    "    'USA': 'US',\n",
    "    'United States': 'US',\n",
    "\n",
    "    'UK': 'GB',\n",
    "    'United Kingdom': 'GB',\n",
    "    'Great Britain': 'GB',\n",
    "    'Ireland': 'GB',\n",
    "    'Scottland': 'GB',\n",
    "    'Wales': 'GB',\n",
    "    'England': 'GB',\n",
    "\n",
    "    'Vietnam': 'VN',\n",
    "\n",
    "    'Russia': 'RU',\n",
    "    \n",
    "    'South Korea': 'KP',\n",
    "    \n",
    "    'Korea': 'KP'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e4bb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sneak peek to the compiled regex pattern\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\b(Albania|Argentina|Armenia|Australia|Austria|Bahrain|Bangladesh|Belarus|Belgium|Brazil|Bulgaria|Ca'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among 354 rows missing country, extracted countries for 53 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "749         UK\n",
       "1952    Greece\n",
       "1993    Canada\n",
       "2202     Spain\n",
       "2687     Kenya\n",
       "Name: description_and_requirements, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result in only 301 rows of missing countries (vs. 354 rows originally)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "escaped_country = [re.escape(c) for c in country_dict.keys()]\n",
    "pattern_country = r'\\b(' + '|'.join(escaped_country) + r')\\b'\n",
    "\n",
    "print(f'Sneak peek to the compiled regex pattern')\n",
    "display(pattern_country[:100])\n",
    "\n",
    "def find_location(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    match = re.search(pattern_country, text, re.IGNORECASE) # case insensitive search\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None\n",
    "\n",
    "missing_country = merged_df[merged_df['country'].isna()].index          # index of rows missing country\n",
    "df_extracted_country = merged_df.loc[missing_country, 'description_and_requirements'].apply(find_location).dropna()\n",
    "print(f'Among {len(missing_country)} rows missing country, extracted countries for {len(df_extracted_country)} rows')\n",
    "display(df_extracted_country.head())\n",
    "\n",
    "merged_df.loc[df_extracted_country.index, 'country'] = df_extracted_country.apply(lambda x: country_dict[x])                # retrieve the country codes\n",
    "print(f'Result in only {len(merged_df[merged_df['country'].isna()])} rows of missing countries (vs. {len(missing_country)} rows originally)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3143857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filling in missing country_state\n",
    "display(len(merged_df[merged_df['country_state'].isna()]))\n",
    "\n",
    "missing_country_state = merged_df.loc[(merged_df['country_state'].isna())].index\n",
    "merged_df.loc[missing_country_state, 'country_state'] = merged_df.loc[missing_country_state, 'country'].dropna().apply(lambda x: f'{x}, NO_STATE' if x else float('nan'))\n",
    "display(len(merged_df[merged_df['country_state'].isna()]))\n",
    "\n",
    "merged_df.to_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c89cab3",
   "metadata": {},
   "source": [
    "# Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a04c19bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 301)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among the samples missing country_state, 8.638% of fradulent samples will be discarded\n"
     ]
    }
   ],
   "source": [
    "n_fraudulent_missing_cs = len(merged_df.loc[(merged_df['country_state'].isna()) & (merged_df['fraudulent'] == 1)])\n",
    "n_missing_cs = len(merged_df.loc[(merged_df['country_state'].isna())])\n",
    "\n",
    "display((n_fraudulent_missing_cs, n_missing_cs))\n",
    "print(f'Among the samples missing country_state, {n_fraudulent_missing_cs/n_missing_cs*100:.3f}% of fradulent samples will be discarded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8daf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
